<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技术相关 on agchen</title>
    <link>https://agchen28.github.io/categories/%E6%8A%80%E6%9C%AF%E7%9B%B8%E5%85%B3/</link>
    <description>Recent content in 技术相关 on agchen</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 04 Apr 2017 22:04:14 +0800</lastBuildDate>
    
	<atom:link href="https://agchen28.github.io/categories/%E6%8A%80%E6%9C%AF%E7%9B%B8%E5%85%B3/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>单例模式</title>
      <link>https://agchen28.github.io/blog/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/</link>
      <pubDate>Tue, 04 Apr 2017 22:04:14 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/</guid>
      <description>单例模式（Singleton Pattern） 有翻译成单件或者单态。反正它的特点就是单，比单身狗还单。
单身狗经常还会搞搞基，单例想搞个基都找不到同类，它是一个独一无二的对象，因为它的类只能被实例化一次。
理解上一般没什么问题，但是实现上还是可以稍微扯下蛋的。
常见的实现方式 public sealed class Singleton { //需要一个额外的Object对象来实现线程同步 private static Object s_lock = new Object(); //一个静态字段来引用一个单实例对象 private static Singleton uniqueInstance; //私有构造器，阻止外部任何代码创建实例 private Singleton() { //初始化的代码 } //一个全局访问点，返回单实例对象 public static Singleton GetSingleton() { //巧妙之处在此：如果对象以及创建，不需要进行线程同步，直接返回 if (uniqueInstance == null) { //锁了Object对象，保证同时只有一个线程执行以下代码块 lock (s_lock) { //再次判断，如果还未创建则进行创建 if (uniqueInstance == null) uniqueInstance = new Singleton(); } } return uniqueInstance; } }  几个关键  私有的构造函数 一个全局访问点GetSingleton 还有就是不得不提的双检锁（Double-Check Locking）技术  这样的实现在工作中很常见。</description>
    </item>
    
    <item>
      <title>lock</title>
      <link>https://agchen28.github.io/blog/lock/</link>
      <pubDate>Sat, 18 Mar 2017 16:24:53 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/lock/</guid>
      <description>说到c#中的锁，可能有些人只知道lock这个东西。其实lock是c#编译器提供给Monitor类的专属关键字。
Monitor只是FCL中提供的混合线程同步构造中的其中一个。
Monitor这么有名气主要是因为它是C#中资历最老，使用最广的线程同步构造。
使用方法 贴一段单例的代码：
public sealed class Singleton { private static Object s_lock = new Object(); private static Singleton uniqueInstance; private Singleton() { } public static Singleton GetSingleton() { if (uniqueInstance == null) { //保证同时只有一个线程执行以下代码块 lock (s_lock) { if (uniqueInstance == null) uniqueInstance = new Singleton(); } } return uniqueInstance; } }  C#编译器看到lock关键字会偷偷帮我们做一些事情，上面的代码等同于：
Boolean lockTaken = false; try { Monitor.Enter(s_lock, ref lockTaken); if (uniqueInstance == null) uniqueInstance = new Singleton(); }finally{ if (lockTaken) Monitor.</description>
    </item>
    
    <item>
      <title>线程同步构造</title>
      <link>https://agchen28.github.io/blog/%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E6%9E%84%E9%80%A0/</link>
      <pubDate>Thu, 02 Mar 2017 11:13:00 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E6%9E%84%E9%80%A0/</guid>
      <description>这个主题涉及内容太多，只能先简单介绍一下。
线程同步构造就是我们俗话说的锁。
锁的作用就是确保一次只有一个线程访问资源。
为什么需要锁呢？
多个线程同时访问共享数据时（必须是共享数据，还有同时访问），锁能防止数据损坏。当然多个线程对共享数据进行只读访问是没有任何问题的。
锁的使用一定是要不得已而为之，因为它有很多缺点。比如影响性能，增加复杂性，还容易出问题。
基元线程同步构造 基元指可以在代码中使用的最简单构造。
有两种基元构造：用户模式（useÏr-mode）和内核模式（kernel-mode）。
用户模式构造 应尽量使用用户模式构造，它们的速度显著快于内核模式的构造。
特点：
使用特殊的CPU指令来协调线程，意味着协调是在硬件中发生的，也意味着操作系统不知道一个线程在用户模式构造中阻塞了，由于操作系统不认为它已经被阻塞了，所以线程池不会创建新线程来替换这种临时阻塞的线程。
这些CPU指令只阻塞线程相当短的时间。
缺点：
想要取得资源但暂时取不到的线程会一直在用户模式中“自旋”，这会浪费CPU时间。
有两种基元用户模式线程同步构造：
 易变构造（volatile construct）
在特定的时间，它在包含一个简单数据类型的变量上执行原子性的读或写操作。
 互锁构造（interlocked construct）
在特定的时间，它在包含一个简单数据类型的变量上执行原子性的读和写操作。
  内核模式构造 内核模式构造比用户模式构造慢得多，需要操作系统的配合。
优点：
操作系统知道一个线程是否在内核模式构造上阻塞了。
可以实现本机和托管线程相互之间的同步。
可以同步一个机器的不同进程中的线程。
混合线程同步构造 所有的线程同步构造都是基于用户模式构造和内核模式构造所构建的，混合了这两种构造的就称为混合线程同步构造。
混合线程同步构造一般结合了这两种线程同步构造的优点，即在没有线程竞争时，混合构造提供了基元用户模式构造的性能优势；当出现线程竞争时，又具备内核模式构造不“自旋”的优势（不浪费cpu时间）。
这里面有个最重要的，也是我们最常用的Monitor，可能大家对这名字还是比较陌生，但是它就是我们平时用得最多的lock。</description>
    </item>
    
    <item>
      <title>dotnet程序执行过程</title>
      <link>https://agchen28.github.io/blog/dotnet%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Thu, 23 Feb 2017 11:05:53 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/dotnet%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/</guid>
      <description>码几行代码 internal class Employee { public Int32 GetYearsEmployed() {...} public virtual String GetProgressReport() {...} public static Employee Lookup(String name) {...} } internal class Manager : Employee { public override string GetProgressReport() {...} }  void M3() { Employee e; Int32 year; e = new Manager(); e = Employee.Lookup(&amp;quot;joe&amp;quot;); year = e.GetYearsEmployed(); e.GetProgressReport(); }  执行过程 初始化： 启动Windows进程，加载CLR，初始化托管堆，创建一个线程并分配1M的线程栈。（如下图：左侧矩形为线程栈，顶部灰色部分加三个点表示已经执行过一些代码。右侧一大坨表示托管堆，M3方法未执行前可能会有其他对象，我们暂且不管。） 调用M3方法： 调用M3方法的时候，CLR会在托管堆上创建M3方法中所需要的类型对象。在这里我们用到Employee，Manager，Int32和String。但Int32和String是常用类型，我们假定它们已经在其他方法中创建了。 关于类型对象：
类型对象就是运行时用来表示该类型的一个对象，这个对象包含一些静态字段。
可以结合实例对象来理解类型对象，实例对象是我们通过调用构造函数创建的对象，类型对象则是CLR自动调用静态构造函数创建的对象（换句话说，我们平时写的静态构造函数就是用来构造这个类型对象的），在一个托管堆中每个类型只有唯一一个类型对象。
 类型对象指针。每个托管堆上的对象都有的东西。
实例对象的类型对象指针会指到它对应的类型对象上。
类型对象的类型对象指针会指到System.Type类型对象上（这是一个特殊的类型对象，Type类型对象的类型对象指针会指向本身）。
System.Object的GetType方法就是返回存储在指定对象的类型对象指针中的地址。
 同步块索引。也是每个托管堆上的对象都有的东西。</description>
    </item>
    
    <item>
      <title>并发型服务器的实现方式</title>
      <link>https://agchen28.github.io/blog/%E5%B9%B6%E5%8F%91%E5%9E%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/</link>
      <pubDate>Mon, 20 Feb 2017 09:55:22 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/%E5%B9%B6%E5%8F%91%E5%9E%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/</guid>
      <description>大部分网络应用程序在编写时都假设一端是客户，另一端是服务器，其目的是让服务器为客户提供特定服务。
一般将这种服务分为两种类型：重复型或并发型。
 重复型：
重复型服务器通过以下步骤进行交互：
1.等待一个客户请求的到来
2.处理客户请求
3.发送响应给客户
4.返回1步
重复型服务器的主要问题发生在2步，这时候它不能为其他客户提供服务。 这种执行模型是同步的，它同时只能处理一个请求，其他的请求都必须按次序等待服务。
这种服务模型处理能力相当低下，假设处理每个请求消耗的时间为N秒，这类服务的QPS就为1/N。
 并发型：
并发型服务器采用以下步骤：
1.等待一个客户请求的到来
2.启动一个新的服务器来处理客户的请求。可能生成一个新的进程、线程或者任务，并依赖底层操作系统的支持。生成新的服务器对用户的全部请求进行处理，处理结束后终止这个服务器。
3.返回1
  并发型服务器的实现方式 每请求每进程 为每一个请求都单独创建一个进程来作为服务。
这种模型的缺点就是代价非常大，内存占用高，进程的创建与销毁时间开销大，而且每台机器所能创建的进程也非常有限。
每请求每线程 由于创建进程开销过大，所以引入了多线程模型。
线程相对于进程来说开销小很多，而且进程之间的每个线程可以共享数据。
每个线程都有一个独立的线程栈，需要占用一定的内存空间。
当并发量非常大的时候，会同时创建大量的线程，这样内存占用就上来了。而且还会出现另外一个问题，就是CPU上下文频繁切换的开销。 每个CPU核心在同一时刻只能处理一件事，操作系统通过将CPU切分时间片的方法，让线程可以较为均匀地使用CPU资源。当线程数量过多的时候，进行上下文切换的消耗就会变大。
这种模型应用的非常广泛，常见的ASP.NET或者Java编写的网络服务一般都属于这种模型。
这类服务可以采用异步I/O的方式来提升服务器性能。不得不提一下C#的异步编程，它提供的一些语法糖写起来就跟写同步代码差不多，简直太傻瓜化、太爽了。
事件驱动 事件驱动这四个字不是很好理解。我把它理解为是为了实现异步I/O的一种处理方式：当执行I/O操作时，绑定一个事件，等I/O操作完成会触发这个事件。（I/O操作包括读写数据库，读写文件，网络请求等一些除CPU计算之外的操作）
采用这种实现方式的有Node和Nginx，利用单线程来避免高并发下内存开销大和上下文切换频繁的问题。
不过它是如何利用单线程就能处理大量的请求呢？
以Node为例来解释一下这个问题。
考虑到目前的网络服务处理的大部分请求都是跟I/O操作相关，而且I/O操作在整个响应过程中一般是最耗时的。如果采用以往同步I/O的方式，就会阻塞这个线程，必须等I/O操作完才能执行接下来的任务。
Node的特点包括单线程和异步I/O。其实在单线程的条件下，真正并发执行的是I/O操作。每个请求按次序等待该线程的处理，不过由于异步I/O的特点，每个请求进来触发I/O操作，即使I/O操作还没执行完，该线程也能继续处理其他请求。
这类服务有个特点就是不处理或者只处理非常少量的CPU计算（这也可以说是它的缺点）。
假设有一个极端的场景：每个请求都不需要I/O操作，但是都需要比较耗时的CPU计算。那么这类服务就会表现得跟重复型服务一样，每个请求都会阻塞服务。虽然Node可以为每个耗时的CPU计算创建一个子进程，如果为每个请求都创建一个进程就会表现得跟每请求每进程一样。当然这种场景现实中应该不会出现，举这个例子主要还是为了说明它的特点。
Goroutine 这是之前瞎捣鼓Go的时候接触到的东西。
Go的出现是为了解决在21世纪多核和网络化环境下越来越复杂的编程问题。
可能大部分技术人员对Google都会有迷之信仰，谷歌出品，必属精品。
Go的并发模型理论指导来自于贝尔实验室的Tony Hoare于1978年发表的鲜为外界所知的关于并发研究的基础文献顺序通信进程 （communicating sequential processes） ，缩写为CSP。（看来什么事情都是理论先行啊，就如当年的XX主义。）
在CSP中，程序是一组中间没有共享状态的平行运行的处理过程，它们之间使用管道进行通信和控制同步。在这样的理论指导下，Go采用Goroutine来实现并行，Goroutine之间通过Channels来通信，而不提倡使用共享数据和锁。
我们可以借助线程来理解Goroutine。
每个线程都会分配到一定大小的内存（一般为2M）作为线程栈，这个栈用来存储当前正在调用或者被挂起的函数的内部变量。如果采用每请求每线程的服务，可能大部分的请求都用不了多少的栈空间，这就造成内存的浪费。
每个Goroutine会分配到一个动态栈，一开始为2KB（应用到网络服务，这可能已经能满足大部分请求所需要的栈空间了）。栈的大小会根据需要动态伸缩，最大可达1GB，虽然一般用不到这么大，但是对于更复杂，更深层次的函数递归调用，可能会需要大一点的栈空间。
由于创建Goroutine的成本非常低，所以创建成百上千Goroutine是非常普遍的。利用Goroutine来处理请求，既能保证资源充分利用，又不会因为执行CPU计算而阻塞服务。
关键地方在于Go的运行时包含一个调度器（它决定了Goroutine调度的效率）。它采用m:n调度，表示会在n个操作系统线程上调度m个Goroutine。n通过GOMAXPROCS这个变量来决定，默认为CPU核心数。
就个人愚见，Go的并发模型真的是非常棒，既能保证资源充分利用，又不会因为执行CPU计算而阻塞服务。事件驱动模型虽然能处理很大的并发请求，但是有其局限性。多线程模型目前的问题主要是同步I/O操作长时间阻塞线程，导致创建大量的线程，如果采用异步I/O的方式相信性能方面会提升很多。</description>
    </item>
    
    <item>
      <title>Storm中Topology的执行过程</title>
      <link>https://agchen28.github.io/blog/storm%E4%B8%ADtopology%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Sat, 11 Feb 2017 16:11:52 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/storm%E4%B8%ADtopology%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/</guid>
      <description> Storm粗浅介绍 Apache Storm是一个开源的，分布式的流式计算系统。
每次看到这么官方的句子都觉得不是很好理解。通俗一点讲，Storm运行在一堆机器上，将我们提交的计算任务分配到各个节点上进行运算，流式指的是数据会持续进来，而我们的计算任务会一直进行。
Storm运行在Java虚拟机上，大部分采用Java和Clojure进行开发，使用ZooKeeper来协调集群中的状态信息。
Storm API的基本概念：
 topology ：Storm分布式计算结构。由一些数据源节点和普通计算节点还有一些边组成的有向无环图。ß
 spout：数据源节点
 bolt：普通计算节点。可以进行写数据到外部存储的操作，比如把数据写到数据库里
 stream：数据流，边
 tuple：记录，存在数据流中的记录
  Storm集群中的基本组件：
 Nimbus
一个Storm集群包含一个主节点。主要职责是管理，协调和监控在集群上运行的topology，包括topology的发布，任务的指派。
 Supervisor
一个Storm集群包含一个或者多个工作节点。supervisor等待nimbus分配任务后生成并监控workers（JVM进程）执行任务。
 Storm DRPC
可选功能。提供了可扩展的分布式RPC能力。
 Storm UI
可选功能。一个Web页面，展示Storm的相关信息，提供一些常用操作。
  Storm的并发机制：
 Node
指配置在Storm集群中的一个服务器，会执行topology的一部分运算。
 Worker
指一个节点上相互独立运行的JVM进程。每个节点可以运行一个或多个worker。可以通过supervisor.slots.port参数配置，每个节点默认会有4个进程。每个topology默认使用一个进程来处理，可以通过config.setNumWorkers方法来设置进程数。如果没有可用的worker，提交的topology会处于等待的状态。
 Executor
worker中的Java线程。Storm默认给每个executor分配一个task，每个task可指派给多个executor，多个task可以指派给同一个executor来执行。
 Task
一个task可以简单理解为某个节点上运行的一个spout或者bolt实例。
  Topology运行流程  Topology提交后，代码会被存放到Nimbus节点下。接着会对该topology进行一番检查，比如当前topology名称是否已存在，bolt和spout命名是否规范等。
 Nimbus把任务分成一个个task，并且给每个task一个编号。系统根据worker的数目，尽量平均分配这些task的执行。
 任务分配好之后，Nimbus将任务信息提交到zookeeper上。
 Supervisor节点会不断的轮询zookeeper集群，领取自己的任务，启动worker进程运行。（领取到的task是nimbus对bolt或者spout实例序列化后的字节码文件，需要进行反序列化后得到spout或者bolt实例，并调用相应的方法。）
 至此整个topology运行起来，除非显式地终止, 否则它会一直运行。
  </description>
    </item>
    
    <item>
      <title>Storm集群搭建</title>
      <link>https://agchen28.github.io/blog/storm%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Sat, 04 Feb 2017 23:30:07 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/storm%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</guid>
      <description>准备  安装java 安装zookeeper  下载  http://storm.apache.org/downloads.html  安装 tar -zxvf apache-storm-1.0.3.tar.gz mkdir data vim conf/storm.yaml #修改配置文件  添加配置项(每行配置前面注意留一个空格)：
storm.zookeeper.servers: - &amp;quot;192.168.142.200&amp;quot; - &amp;quot;192.168.142.201&amp;quot; - &amp;quot;192.168.142.202&amp;quot; nimbus.host: &amp;quot;192.168.142.200&amp;quot; storm.local.dir: &amp;quot;/opt/storm/data&amp;quot;  启动 nohup bin/storm nimbus &amp;amp; #启动nimbus nohup bin/storm supervisor &amp;amp; #启动supervisor nohup bin/storm ui &amp;amp; #启动UI  访问Storm UI http://192.168.142.200:8080/</description>
    </item>
    
    <item>
      <title>Kafka集群搭建</title>
      <link>https://agchen28.github.io/blog/kafka%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Sat, 04 Feb 2017 23:19:49 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/kafka%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</guid>
      <description>简介 Apache Kafka是一个分布式消息队列系统。
相关概念  producer：生产者，负责将消息发布到kafka集群。
 consumer：消费者，从kafka集群中消费消息。
 broker：kafka集群中包含的服务器。
 topic：消息的主题。
 partition：每个 topic 包含一个或多个 partition。
  消息的存储 topic被分成一个或多个patition，每个patition物理上对应一个文件夹（该文件夹存储该 patition 的所有消息和索引文件）。
无论消息是否被消费，kafka 都会保留所有消息。有两种策略可以删除旧数据：
1. 基于时间：log.retention.hours=168
2. 基于大小：log.retention.bytes=1073741824
应用场景  日志收集
 用户行为数据收集
  搭建 环境准备  三台Linux服务器：
192.168.142.200 linux01
192.168.142.201 linux02
192.168.142.202 linux03
 依赖于Zookeeper，所以需要先安装好Zookeeper  下载解压 wget http://apache.opencas.org/kafka/0.9.0.1/kafka_2.11-0.9.0.1.tgz tar -zxvf kafka_2.11-0.9.0.1.tgz  修改配置文件 #broker.id=0 每台服务器的broker.id都不能相同 log.dirs=/opt/kafka/logs/ #hostname host.name=192.168.142.200 #设置zookeeper的连接端口 zookeeper.connect=192.168.142.200:2181,192.168.142.201:2181,192.168.142.202:2181  启动服务 ./kafka-server-start.sh -daemon ../config/server.properties #检查服务是否启动 jps #创建Topic .</description>
    </item>
    
    <item>
      <title>Zookeeper集群搭建</title>
      <link>https://agchen28.github.io/blog/zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Sat, 28 Jan 2017 22:28:31 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</guid>
      <description>Zookeeper是一个分布式协调服务。
准备 三台Linux服务器：
192.168.142.200 linux01
192.168.142.201 linux02
192.168.142.202 linux03
安装JDK yum list java* yum -y install java-1.8.0-openjdk*  下载Zookeeper解压 cd /opt/zookeeper/ wget http://mirrors.cnnic.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz tar -zxvf zookeeper-3.4.6.tar.gz  修改配置文件 cp zoo_sample.cfg zoo.cfg  需要修改的配置项：
tickTime=2000 initLimit=10 syncLimit=5 dataDir=/opt/zookeeper/data clientPort=2181 server.1=192.168.142.200:2888:3888 server.2=192.168.142.201:2888:3888 server.3=192.168.142.202:2888:3888 #server.1 这个1是服务器的标识也可以是其他的数字， 表示这个是第几号服务器，用来标识服务器，这个标识要写到快照目录下面myid文件里 #第一个端口是master和slave之间的通信端口，默认是2888，第二个端口是leader选举的端口，集群刚启动的时候选举或者leader挂掉之后进行新的选举的端口默认是3888  创建myid文件 #server1 echo &amp;quot;1&amp;quot; &amp;gt; /opt/zookeeper/data/myid #server2 echo &amp;quot;2&amp;quot; &amp;gt; /opt/zookeeper/data/myid #server3 echo &amp;quot;3&amp;quot; &amp;gt; /opt/zookeeper/data/myid  启动服务 ./zkServer.sh start #启动服务（3台都需要操作） ./zkServer.sh status #检查服务器状态 jps #jps(Java Virtual Machine Process Status Tool)是JDK 1.</description>
    </item>
    
    <item>
      <title>垃圾回收器</title>
      <link>https://agchen28.github.io/blog/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/</link>
      <pubDate>Tue, 13 Dec 2016 11:11:42 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/</guid>
      <description> 找到存活的对象 引用计数 这是一种简单但速度很慢的垃圾回收技术。该技术常被用来说明垃圾收集的工作方式，看过介绍Java，JavaScript，.NET中垃圾回收器的实现都提到这个东西。
给每个对象一个引用计数器，当有引用连接到对象时，计数器加1，当引用离开作用域或者被置为null时，计数器减1。垃圾回收器扫描全部对象，当计数器为0时，释放该对象。
这种方式有个缺陷，当出现循环引用时，该被释放的对象的引用计数却不为0。
引用跟踪 将所有引用了堆上对象的变量称为根。检查所有活动根，查看它们引用了哪些对象，如果引用了堆上的对象，会继续检查该对象中的根，这样就可以确保所有“活”的对象都被访问到，而且解决了“交互自引用的对象组”的问题。
清理 停止-复制（stop-and-copy） 先暂停程序的运行（不属于后台回收模式），将所有存活的对象 复制到新堆并保持紧凑排列。
这种方式有两个问题：
一来需要有两个堆，相当于需要多一倍的空间。
二来当程序运行稳定后，可能只产生少量垃圾，如果仍然复制所有内存显然有点浪费。
标记-清扫（mark-and-sweep） 根据引用跟踪算法，为所有存活的对象做上标记。当标记工作完成时，清理动作开始，没被标记的对象都将被清理掉。这时堆中的空间是不连续的，所以一般接下来都会有个重新整理的操作。
优化方案 自适应 Java虚拟机根据清理效果，如果所有对象都很稳定，垃圾回收器的效率降低的话，就切换到“标记-清扫”模式；同样，根据“标记-清扫”的效果，如果堆中出现很多碎片，就切换回“停止-复制”模式。
分代 CLR和Java中的垃圾回收器都有分代的概念。
以CLR中的GC为例，介绍一下代的概念。
垃圾回收器会假设你的代码中（大量研究表明，这些假设对于现今大多数应用程序都是成立的）：
 对象越新，生存期越短。
 对象越老，生存期越长。
 回收堆的一部分，速度快于回收整个堆。
  工作原理：
 CLR的GC支持三代：第0，第1，第2。CLR初始化时为每代选择预算，这个预算会根据垃圾回收效果动态调节。
 托管堆在初始化时不包含对象，这时添加的对象被称为第0代，垃圾回收器从未检查过它们。
 根据对第0代的预算容量，如果分配一个新对象造成第0代超过预算，就必须启动一次垃圾回收。垃圾回收后，没有被清理掉的对象升级为第1代，第0代的空间现在是空的。
 继续在第0代为新的对象分配内存，如果第0代又超出预算，再启动一次垃圾回收。这时，如果第1代没有超出预算就只对第0代进行回收，跟上述一样。如果第1代也超出了预算，垃圾回收器就会检查第0代还有第1代中的所有对象。第1代被回收后存活下来的对象就会升级为第2代，第0代中存活的对象升级为第1代，第0代空间为空。
 如果一次垃圾回收后，没有回收到足够的内存，会再执行一次完整的回收。如果还是不够，就会抛出OutOfMemoryException异常。
  </description>
    </item>
    
    <item>
      <title>SpringBoot搭建项目</title>
      <link>https://agchen28.github.io/blog/springboot%E6%90%AD%E5%BB%BA%E9%A1%B9%E7%9B%AE/</link>
      <pubDate>Sun, 09 Oct 2016 13:04:32 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/springboot%E6%90%AD%E5%BB%BA%E9%A1%B9%E7%9B%AE/</guid>
      <description>Srping Boot简介 Spring Boot就是Spring一些库的集合，用来简化Spring应用的搭建及开发。
特点  配置简单
 内嵌tomcat，可以直接打成jar包运行
  搭建demo 根据官方文档，快速搭建Spring Boot项目 http://projects.spring.io/spring-boot/
 添加Maven依赖
  &amp;lt;parent&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-parent&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.5.0.RELEASE&amp;lt;/version&amp;gt; &amp;lt;/parent&amp;gt; &amp;lt;dependencies&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;/dependencies&amp;gt;   编写控制器
  @RestController public class HelloController { @RequestMapping(value = {&amp;quot;/hello&amp;quot;, &amp;quot;/hi&amp;quot;}, method = RequestMethod.GET) public String say() { return &amp;quot;Hello&amp;quot;; } }   Spring应用启动类  import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.</description>
    </item>
    
    <item>
      <title>Redis的Script</title>
      <link>https://agchen28.github.io/blog/redis%E7%9A%84script/</link>
      <pubDate>Fri, 09 Sep 2016 23:28:44 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/redis%E7%9A%84script/</guid>
      <description>EVAL Redis 2.6.0开始，通过内置的Lua解释器，可以使用EVAL命令对Lua脚本进行求值。
EVAL script numkeys key [key ...] arg [arg ...]   script 参数是一段 Lua 5.1 脚本程序，它会被运行在 Redis 服务器上下文中。
 numkeys 参数用于指定键名参数的个数。
 key [key &amp;hellip;] 表示键名参数，从 EVAL 的第三个参数开始算起，表示在脚本中所用到的那些 Redis 键，这些键名参数可以在 Lua 中通过全局变量 KEYS 数组，用 1 为基址的形式访问(如： KEYS[1] ， KEYS[2] )。
 arg [arg &amp;hellip;] 是附加参数，可以在 Lua 中通过全局变量 ARGV 数组访问。
  &amp;gt; eval &amp;quot;return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}&amp;quot; 2 key1 key2 first second 1) &amp;quot;key1&amp;quot; 2) &amp;quot;key2&amp;quot; 3) &amp;quot;first&amp;quot; 4) &amp;quot;second&amp;quot;  在 Lua 脚本中，可以使用两个不同函数来执行 Redis 命令：</description>
    </item>
    
    <item>
      <title>Redis的持久化</title>
      <link>https://agchen28.github.io/blog/redis%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96/</link>
      <pubDate>Fri, 05 Aug 2016 12:58:40 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/redis%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96/</guid>
      <description>redis提供两种持久化方式。
RDB RDB 保存的是数据集。
优点  RDB 是一个非常紧凑的文件，它保存了 Redis 在某个时间点上的数据集。
 RDB 非常适用于灾难恢复：可以（在加密后）将它传送到别的数据中心。
 RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。
 RDB 在恢复大数据集时的速度比 AOF 要快。
  缺点  服务器故障时可能会丢失几分钟的数据
 当数据集非常庞大时，fork()子进程会非常耗时，造成服务器在几毫秒内停止处理客户端，如果这时候CPU非常紧张的话，停止时间可能会长达一秒
  AOF(AppendOnly File) AOF 记录的是所有写操作命令，可以在后台对AOF 文件进行重写来减小文件的大小。
优点  使用 AOF 持久化会让 Redis 变得非常耐久：可以设置不同的 fsync 策略。默认策略为每秒钟 fsync 一次，也就是每秒钟将缓存中的AOF写到磁盘上。
 AOF文件过大时，会自动在后台进行重写，重写过程原有的AOF文件不会丢失。
 AOF文件容易被读懂分析。
  缺点  对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。
 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。</description>
    </item>
    
    <item>
      <title>Redis的Replication</title>
      <link>https://agchen28.github.io/blog/redis%E7%9A%84replication/</link>
      <pubDate>Mon, 01 Aug 2016 12:57:29 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/redis%E7%9A%84replication/</guid>
      <description>主从复制功能 主从复制（master-slave replication）功能可以让从服务器成为主服务器的精确复制品。
Redis 复制功能的几个特点：
 Redis 使用异步复制。
 一个主服务器可以有多个从服务器。
 复制功能不会阻塞主服务器
 复制功能也不会阻塞从服务器
 复制功能可以单纯地用于数据冗余
  配置 从服务器的配置文件添加下面配置：
slaveof 192.168.1.1 6379 masterauth &amp;lt;password&amp;gt;  也可以动态设置从服务器的主服务器：
SLAVEOF 192.168.1.1 10086 config set masterauth &amp;lt;password&amp;gt;  运作原理 当建立一个从服务器时，从服务器向主服务器发送一个 SYNC 命令。接到 SYNC 命令的主服务器将开始执行 BGSAVE ，并在保存操作执行期间，将所有新执行的写入命令都保存到一个缓冲区里面。
当 BGSAVE 执行完毕后，主服务器将执行保存操作所得的 .rdb 文件发送给从服务器，从服务器接收这个 .rdb 文件， 并将文件中的数据载入到内存中。
之后主服务器会以 Redis 命令协议的格式，将写命令缓冲区中积累的所有内容都发送给从服务器。
应用 读写分离 redis的主从同步功能常见的应用就是读写分离：将读的压力分担到从服务器身上，主服务器只负责写的操作，从而缓解主服务器的压力。
主从切换 假设主服务器挂掉，使用 SLAVEOF NO ONE 命令将一个从服务器变成主服务器，其他从服务器设置为与该服务器同步，从而实现主从切换。</description>
    </item>
    
    <item>
      <title>Redis中的数据类型</title>
      <link>https://agchen28.github.io/blog/redis%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</link>
      <pubDate>Sat, 09 Jul 2016 12:55:43 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/redis%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</guid>
      <description>Redis中的数据类型包括：String、Hash、List、Set、SortedSet。
String 可以用来存放字符串或者数值类型，对于数值类型可以进行增加或减少操作。
实现一个简单的分布式锁 客户端执行命令：
SET resource-name anystring NX EX max-lock-time  如果服务端返回OK，那么获得锁。如果返回nil，请稍后再试。
计数器和限速器 使用 INCR 命令来统计用户一个时间段的操作次数，限速器可以用来限制一个公开API在一个时间段内的请求次数。
Bitmap Bitmap 对于一些特定类型的计算非常有效。
比如需要记录用户每天是否上线，计算总共上线天数，就可以使用 SETBIT 和 BITCOUNT 来实现。
假设我们需要为每个用户记录一个特殊属性，例如是否活跃用户，是否黑名单用户。我们可以将属性值作为key，用户id作为偏移量，通过 SETBIT 和 GETBIT 命令来实现。
Hash 也可以用来存储字符串和数值类型，数值类型可以增减操作。
适合用来存储对象，每个key下面的field对应该对象的一个属性，对该对象任一个属性读写操作的时间复杂度都是O(1)。
使用 HMGET 和 HMSET 命令可以读写多个field，时间复杂度为O(N)，N是给定的field数量。
使用 HGETALL 命令会返回该hash的所有field和value，时间复杂度是O(N)，N为该hash的大小。
List List是有序的列表，支持双端操作，还有阻塞的操作，可以用来实现阻塞队列。
事件提醒 我们经常会使用轮询的方式来查询List中是否有新元素达到。 另一种更好的方式是，使用 BLPOP 或者 BRPOP ，在新元素到达时立即进行处理，而新元素还没到达时，就一直阻塞住，避免轮询占用资源。
安全队列 使用 RPOPLPUSH 命令(或者它的阻塞版本 BRPOPLPUSH )实现安全队列。该命令返回一个消息，并把该消息塞入一个备份列表中，当消息处理成功后再用 LREM 命令将这个消息从备份表删除。
循环列表 给 RPOPLPUSH 命令的两个参数传入相同的key，可以不停地循环取出该列表中的元素。
循环列表可以应用在服务器的监控程序，不停地监控一组服务是否正常工作。
Set set为无序，且不重复的集合，且提供O(1)复杂度度的快速查找。set集合支持集合的并，交，差操作。
SortedSet 可排序的集合，根据score进行排序，如果两个score相同，则按照value的字典序排序。</description>
    </item>
    
    <item>
      <title>Mongodb安装记录</title>
      <link>https://agchen28.github.io/blog/mongodb%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Wed, 08 Jun 2016 11:05:10 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/mongodb%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/</guid>
      <description>下载 https://www.mongodb.com/download-center#community
选择相应的版本下载
安装 mkdir mongodb cd mongodb mkdir db mkdir logs tar -zxvf mongodb-linux-x86_64-3.4.3.tgz cd mongodb-linux-x86_64-3.4.3/bin vim mongodb.conf  mongodb.conf内容：
dbpath=/opt/mongodb/db logpath=/opt/mongodb/logs/mongodb.log port=27017 fork=true nohttpinterface=true bind_ip=192.168.142.200 #auth=true #开启用户认证  启动 /opt/mongodb/mongodb-linux-x86_64-3.4.3/bin/mongod --config /opt/mongodb/mongodb-linux-x86_64-3.4.3/bin/mongodb.conf  检测 ps -ef |grep mongo #检测后台进程是否存在 netstat -lntp | grep 27017 ./mongo 192.168.142.200:27017  开机启动 vim /etc/init.d/mongodb chmod +x /etc/init.d/mongodb #赋予执行权限 service mongodb start/stop chkconfig mongodb on #设为开机启动  脚本如下（看不懂）：
#!/bin/bash # mongod - Startup script for mongod # chkconfig: 35 80 15 # description: Mongo is a scalable, document-oriented database.</description>
    </item>
    
    <item>
      <title>Redis安装记录</title>
      <link>https://agchen28.github.io/blog/redis%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Wed, 08 Jun 2016 11:04:56 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/redis%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/</guid>
      <description> Redis简介 Redis是一个开源的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。
Redis优点  速度快
 支持丰富的数据类型: Redis支持最大多数开发人员已经知道如列表、集合、可排序集合、哈希等数据类型。
 操作都是原子的：所有 Redis的操作都是原子，从而确保当两个客户同时访问Redis服务器得到的是更新后的值。
  下载安装 wget http://download.redis.io/releases/redis-3.2.8.tar.gz tar xzf redis-3.2.8.tar.gz cd redis-3.2.8 make #可使用root用户执行`make install`，将可执行文件拷贝到/usr/local/bin目录下。这样就可以直接敲名字运行程序了。 make install  设置开机启动 启动脚本 redis_init_script 位于Redis的 /utils/ 目录下。 - 根据启动脚本要求，将修改好的配置文件以端口为名复制一份到指定目录。需使用root用户。
mkdir /etc/redis cp redis.conf /etc/redis/6379.conf   修改配置文件  bind:ip地址 port：端口号。默认6379 requirepass:设置密码 slaveof：从服务器需要配置 masterauth：主服务器的密码   将启动脚本复制到/etc/init.d目录下，本例将启动脚本命名为redisd（通常都以d结尾表示是后台自启动服务）。  cp redis_init_script /etc/init.d/redisd   设置为开机自启动
在启动脚本开头添加如下两行注释以修改其运行级别
#!/bin/sh # chkconfig: 2345 90 10 # description: Redis is a persistent key-value database#  #设置为开机自启动服务 chkconfig redisd on #打开服务 service redisd start #关闭服务 service redisd stop   检测 ps -ef |grep redis #检测后台进程是否存在 netstat -lntp | grep 6379 #检测6379端口是否在监听 redis_cli -a 123456 #使用`redis-cli`客户端检测连接是否正常  </description>
    </item>
    
    <item>
      <title>CSharp中的委托</title>
      <link>https://agchen28.github.io/blog/csharp%E4%B8%AD%E7%9A%84%E5%A7%94%E6%89%98/</link>
      <pubDate>Thu, 26 May 2016 09:33:54 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/csharp%E4%B8%AD%E7%9A%84%E5%A7%94%E6%89%98/</guid>
      <description>委托也是C#中的一种类型，只不过它比其他类型来得特殊一点，该类型的实例就是方法的包装器。也就是说，我们可以把一个方法塞到一个委托对象里面，然后通过使用这个对象来使用塞到里面的方法。
既然委托是一个类，我们就来看一下这个类中有哪些重要的方法和字段。
//当我们定义一个委托时 internal delegate void Feedback(Int32 value); //编译器会定义一个完整的类： internal class Feedback : System.MulticastDelegate{ //构造器 public Feedback(Object @obejct,IntPtr method); //这个方法的原型和你定义的委托一样 //当在一个委托对象后面加上括号调用的时候其实就是调用Invoke方法 public virtual void Invoke(Int32 value); //以下方法实现对回调方法的异步回调 public virtual IAsyncResult BeginInvoke(Int32 value, AsyncCallback callback, Object @object); public virtual void EndInvoke(IAsyncResult result); }  所有的委托类型都派生自MulticastDelegate，MulticastDelegate又派生自System.Delegate。MulticastDelegate有三个最重要的非公共字段。
 _target Oject类型 指出方法的对象，如果是静态方法置为null。
 _methodPtr IntPtr类型 一个内部的整数值，CLR用它标识要回调的方法。
 _invocationList Object类型 该字段通常为null。构造委托链时它引用一个委托数组。
  </description>
    </item>
    
    <item>
      <title>虚拟机安装记录</title>
      <link>https://agchen28.github.io/blog/%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Wed, 27 Apr 2016 21:07:37 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/</guid>
      <description>本编记录用VMware虚拟机安装CentOS6.8，以及一些常用工具，以作备忘。
下载安装文件 官网下载：https://www.centos.org/
VM创建新的虚拟机 选择典型-&amp;gt;稍后安装操作系统-&amp;gt;选择linux，设置CentOS 64位-&amp;gt; 填写虚拟机名称-&amp;gt;设置CD/DVD路径，选择使用ISO映像文件-&amp;gt;一路默认直到完成
安装操作系统 开启虚拟机-&amp;gt;进入安装程序-&amp;gt;选择skip-&amp;gt;选择简体中文-&amp;gt;一路下一步-&amp;gt; 设置主机名-&amp;gt;配置网络，编辑，勾选自动连接-&amp;gt;继续下一步-&amp;gt;设置root密码-&amp;gt; 点击下一步开始安装
安装常用工具 yum install vim
yum install wget
yum install tree
yum install lrzsz
yum install tar
yum install unzip
yum install -y gcc g++ gcc-c++ make
配置IP vim /etc/sysconfig/network-script/ifcfg-eth0
IPADDR=192.168.91.100
GATEWAY=192.168.91.2
NETMASK=255.255.255.0
BOOTPROTO=static
设置完ip可以通过xshell连接
修改hosts文件
vim /etc/hosts
192.168.91.100 linux01
立即生效
source etc/hosts
设置dns
vim /etc/resolf.cnf
关闭防火墙
chkconfig iptables off
service iptables stop</description>
    </item>
    
    <item>
      <title>泛型</title>
      <link>https://agchen28.github.io/blog/%E6%B3%9B%E5%9E%8B/</link>
      <pubDate>Wed, 27 Apr 2016 11:33:01 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/%E6%B3%9B%E5%9E%8B/</guid>
      <description>许多原因促成了泛型的出现，最引人注目的一个原因就是为了创建容器类，利用泛型就可以指定容器内要持有什么样的对象。
泛型就是参数化的类型，使代码可以应用于多种类型。
Java中的泛型 Java SE5引入了泛型。
了解一下Java是如何实现泛型的，以及为何采用这种设计方案。
实现方案 看个例子：
public class Test { public static void main(String[] args) { Class c1 = new ArrayList&amp;lt;Integer&amp;gt;().getClass(); Class c2 = new ArrayList&amp;lt;String&amp;gt;().getClass(); System.out.println(c1 == c2);//true System.out.println(c1.toString());//class java.util.ArrayList System.out.println(c2.toString());//class java.util.ArrayList } }  我们会发现ArrayList&amp;lt;Integer&amp;gt;和ArrayList&amp;lt;String&amp;gt;在运行时被认为是相同的类型，事实上它们在运行时就是相同的类型。
Java采用擦除来实现泛型。
ArrayList&amp;lt;Integer&amp;gt;和ArrayList&amp;lt;String&amp;gt;这两种形式都被擦除成它们的“原生”类型，即ArrayList。
Java泛型的核心概念：告诉编译器想使用什么类型，然后编译器帮你处理一切细节。
就个人愚见，Java的泛型概念只存在于Java编译器，它令我们有使用泛型的感觉，对于运行时来说它根本不知道泛型是什么鬼东西。
采用这种设计方案的原因 因为泛型不是在Java语言出现就有的组成部分，所以把泛型加入到Java中需要考虑一些兼容性问题。
Java泛型不仅必须支持向后兼容性，而且还要支持“迁移兼容性”。为了不破坏现有类库的情况下将泛型融入Java语言，Java的设计者们和从事此问题相关工作的各个团队决策认为擦除是唯一可行的解决方案。这是一种折中的不得已而为之的实现方案。
“迁移兼容性”：
要使得泛化的客户端可以用非泛化的类库来使用，反之亦然，这被称为“迁移兼容性”。
.NET中的泛型 来看一下.NET中如何实现泛型。
泛型也不是.NET一出现就有的，在CLR2.0中被加入。
开放类型与封闭类型 我们知道，CLR会为应用程序使用到的各种类型在托管堆上创建所谓的类型对象。
具有泛型参数的类型也是类型，同样会有自己的类型对象。
 开放类型
具有泛型类型参数的类型称为开放类型，CLR禁止构造开放类型的任何实例。这类似与禁止构造接口类型的实例。（即使通过反射也没办法）
 封闭类型
为所有类型参数都传递了实际的数据类型，类型就会成为封闭类型。封闭类型是可以用来构造实例的。
如果只传递了部分类型参数，会创建新的开放类型对象。
  至此我们可以明白，CLR根据类型参数为每个泛型创建不同的类型对象，所以在运行时，每个泛型都有自己的具体类型。.NET中的这种实现方式使得泛型是一个纯粹的泛型。
代码爆炸 这是.NET中泛型实现方式的一个缺点。
使用泛型类型参数的方法，在进行JIT编译时，CLR要为每种不同的方法/类型组合生成本机代码，这种现象成为代码爆炸。
两个优化：
CLR只会为一个方法/类型组合编译一次代码。</description>
    </item>
    
    <item>
      <title>JavaScript中的function</title>
      <link>https://agchen28.github.io/blog/javascript%E4%B8%AD%E7%9A%84function/</link>
      <pubDate>Sat, 23 Apr 2016 08:50:12 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/javascript%E4%B8%AD%E7%9A%84function/</guid>
      <description>JavaScript设计得最出色的就是它的函数的实现。它几乎近于完美。&amp;ndash;Douglas Crockford
第一类值（first-class values） JavaScript中的函数就是对象。
可以使用对象的地方都可以使用函数。
比如可以赋值给变量，保存在其他对象中，可以作为函数的参数或者作为函数的返回值。
函数跟其他对象不一样的地方在于可以在它后面加个括号调用它。
据我了解，函数作为第一类值的语言还有Go，Lua。这种设计使得函数使用起来非常灵活。
C#中实现方法的传递 方法与函数的区别以我的理解来说，方法是面向对象中对于函数的说法，当一个函数属于一个对象，该函数就称为该对象的方法。
由于C#和Java属于完全面向对象编程语言，所有的函数都是某个对象的方法，即使静态方法也是属于某个类型对象的方法。
所谓编程，就是将一组需求分解成一组函数和数据结构的技能。
那么所谓面向对象编程，就是将一组需求分解成一组对象，对象中就包含与本身相关的数据和用来操作数据的方法。
C#中通过委托（delegate）来实现类似的操作。
委托也是C#中的一种类型，只不过它比其他类型来得特殊一点，该类型的实例就是方法的包装器。也就是说，我们可以把一个方法塞到一个委托对象里面，然后通过使用这个对象来使用塞到里面的方法。
调用  方法调用模式
当一个函数属于一个对象时，我们通过使用该对象的点操作符来调用该函数，这种调用方式就是方法调用模式。
方法内部的this会被绑定到该对象，这个绑定是在调用的时候发生。
var myObject = { value: 0, incrament: function (inc) { this.value += typeof inc === &#39;number&#39; ? inc : 1; } }; myObject.increment(); document.writeln(myObject.value);//1 myObject.increment(2); document.writeln(myObject.value);//3  函数调用模式
当一个函数并非一个对象的属性时，那么它就是被当作一个函数来调用。
此模式调用函数时，this被绑定到全局对象。这是语言设计上的一个错误。倘若语言设计正确，那么当内部函数被调用时，this应该仍然绑定到外部函数的this变量。（Douglas Crockford大神的原话）
看解决方案：
//给myObject增加一个double方法。 myObject.double = function () { var that = this; var helper = function () { that.</description>
    </item>
    
    <item>
      <title>JavaScript中的对象</title>
      <link>https://agchen28.github.io/blog/javascript%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/</link>
      <pubDate>Thu, 21 Apr 2016 09:34:12 +0800</pubDate>
      
      <guid>https://agchen28.github.io/blog/javascript%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/</guid>
      <description>在JavaScript中，数组是对象，函数是对象，正则表达式是对象，当然，对象自然也是对象。
JavaScript里的对象是无类型（class-free）的。它对新属性的名字和属性的值没有限制。
原型（prototype）  原型对象
每个对象都链接到一个原型对象，并且它可以从中继承属性（听起来是不是像CLR中的类型对象）。所有通过对象字面量创建的对象都连接到Object.prototype,它是JavaScript中的标配对象。
原型链接在更新时是不起作用的。当我们对某个对象做出改变时，不会触及改对象的原型。
原型链接只有在检索值的时候才被用到。如果我们尝试去获取对象的某个属性值，但该对象没有此属性名，那么JavaScript会试着从原型对象中获取属性值。如果那个原型对象也没有该属性，那么再从它的原型中找，依次类推，知道该过程最后到达终点Object.prototype。如果想要的属性完全不存在于原型链中，那么结果就是undefined值。
原型关系是一种动态的关系。如果我们添加一个新的属性到原型中，该属性会立即对所有基于该原型创建的对象可见。  //这种继承方式被称作原型式继承 //通过修改对象的原型对象来实现 if (typeof Object.create !== &#39;function&#39;) { Object.create = function (o) { var F = function () { }; F.prototype = o; return new F(); }; } var another_stooge = Object.create(stooge);   构造函数、原型对象与实例对象之间的关系  function SuperType() { this.property = true; } SuperType.prototype.getSuperValue = function () { return this.property; }; function SubType() { this.subproperty = false; } //继承了SuperType SubType.</description>
    </item>
    
  </channel>
</rss>